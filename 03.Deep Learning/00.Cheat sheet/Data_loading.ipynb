{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loader and Batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For every NN in MLP this is the very begining step to load and create batches from the available data.  \n",
    "Interms of Machine learning it is refeered to as Data preprocessing and splitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scenario-1: Data is in CSV format  \n",
    "`For multiclass classification and regression problems/data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as T\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step-1 loading data from the csv file. and splitting it\n",
    "def load_data(pth):\n",
    "\n",
    "    data = pd.read_csv(pth)\n",
    "\n",
    "    data.drop(['date'], axis = 1, inplace = True) ## Feature Engineering, droping columns, splitting columns and replacing\n",
    "\n",
    "    y = data['DAX'].values # Take target column\n",
    "    x = data.drop(['DAX'], axis = 1).values # Take feature column\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.1, random_state = 0)\n",
    "\n",
    "    x_train = T.tensor(x_train.astype(np.float32)) # numpy array to Tensors to train MLP.\n",
    "    x_test = T.tensor(x_test.astype(np.float32))\n",
    "\n",
    "    y_train = T.tensor(y_train.astype(np.float32))\n",
    "    y_test = T.tensor(y_test.astype(np.float32))\n",
    "\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step-2 Create batches\n",
    "def to_batches(x_train, x_test, y_train, y_test, batch_size):\n",
    "\n",
    "    n_batches = x_train.shape[0] // batch_size # 11 / 3 = 3.66 -> 3\n",
    "    n_batches_test = x_test.shape[0] // batch_size\n",
    "\n",
    "    indexes = np.random.permutation(x_train.shape[0])\n",
    "    indexes_test = np.random.permutation(x_test.shape[0])\n",
    "\n",
    "\n",
    "    x_train = x_train[indexes]\n",
    "    y_train = y_train[indexes]\n",
    "\n",
    "    x_test = x_test[indexes_test]\n",
    "    y_test = y_test[indexes_test]\n",
    "\n",
    "    x_train = x_train[ :batch_size * n_batches ].reshape(n_batches, batch_size, x_train.shape[1])\n",
    "    y_train = y_train[ :batch_size * n_batches ].reshape(n_batches, batch_size, 1)\n",
    "    \n",
    "    x_test = x_test[ :batch_size * n_batches_test ].reshape(n_batches_test, batch_size, x_test.shape[1])\n",
    "    y_test = y_test[ :batch_size * n_batches_test ].reshape(n_batches_test, batch_size, 1)\n",
    "\n",
    "\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "x_train_batches, x_test_batches, y_train_batches, y_test_batches = to_batches(x_train, x_test, y_train, y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, The top one is the way to create data batches for our neural networks.  \n",
    "But, we hard coded a lot of things.  \n",
    "There is a other way to do it.  \n",
    "Using custom `Dataloader & DataLoader pytorch function` to create batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating Custom Dataloader for pytorch DataLoader to create Batches.\n",
    "import torch as T\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):   # Dataset in CustomDataset is from torch.utils.data\n",
    "    def __init__(self, data_path):\n",
    "        data = pd.read_csv(data_path)\n",
    "        data.columns = [x.replace('\"','').replace(' ','') for x in data.columns] # to relace anything in the columns\n",
    "        # Do the F.E like dropping, adding columns\n",
    "        self.x = data.drop('target', axis=1).values\n",
    "        self.y = data['target'].values\n",
    "        self.n_samples = self.x.shape[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "\n",
    "pth= ''\n",
    "data = CustomDataset(data_path=pth)\n",
    "data = DataLoader(dataset=data, batch_size=10, shuffle=True)\n",
    "trainset = data[0:20]\n",
    "testset = data[20:] # Depends on no.of batches \n",
    "# this trainset contain features and labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image data.  \n",
    "What if we got data in the form of images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you need to load an image dataset, it's more convenient to use the `ImageFolder` class from the `torchvision.datasets` module.\n",
    "\n",
    "To do so, you need to structure your data as follows:\n",
    "\n",
    "```\n",
    "root\n",
    "|_class1\n",
    "    |_xxx.png\n",
    "|_class2\n",
    "    |_xxx.png\n",
    "```\n",
    "\n",
    "that means that each class has its own directory.\n",
    "\n",
    "By giving this structure, the name of the class will be taken by the name of the folder!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "root_dir = r'C:\\Users\\rnr31\\Documents\\GitHub\\Data_Science_2022\\03.Deep Learning\\04. DataLoader\\image_data'\n",
    "\n",
    "train_transforms = transforms.Compose([transforms.Resize(255),\n",
    "                                       transforms.RandomRotation(30),\n",
    "                                       transforms.RandomResizedCrop(224),\n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize([0.5, 0.5, 0.5],\n",
    "                                                            [0.5, 0.5, 0.5])])\n",
    "\n",
    "test_transforms = transforms.Compose([transforms.Resize(255),\n",
    "                                      transforms.CenterCrop(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.5, 0.5, 0.5],\n",
    "                                                           [0.5, 0.5, 0.5])])\n",
    "\n",
    "# Pass transforms in here, then run the next cell to see how the transforms look\n",
    "train_data = datasets.ImageFolder(root_dir + '/train', transform=train_transforms)\n",
    "test_data = datasets.ImageFolder(root_dir + '/test', transform=test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_loader = DataLoader(train_data, batch_size=2, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=2, shuffle=True)\n",
    "# Batch size depends on the count of total images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(image, ax=None, title=None, normalize=False):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    image = image.numpy().transpose((1, 2, 0))\n",
    "\n",
    "    if normalize:\n",
    "        mean = np.array([0.485, 0.456, 0.406])\n",
    "        std = np.array([0.229, 0.224, 0.225])\n",
    "        image = std * image + mean\n",
    "        image = np.clip(image, 0, 1)\n",
    "\n",
    "    ax.imshow(image)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.tick_params(axis='both', length=0)\n",
    "    ax.set_xticklabels('')\n",
    "    ax.set_yticklabels('')\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR CODE HERE\n",
    "\n",
    "# Run this to test your data loaders\n",
    "images, labels = next(iter(train_loader))\n",
    "imshow(images[9], normalize=False)\n",
    "labels[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Dataset from Pytorch  \n",
    "Refer to MNIST."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Data in CSV format\n",
    "What if the path and labels of the images are available in the CSV format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>my_dataset/image1.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>my_dataset/image2.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    path  label\n",
       "0  my_dataset/image1.png      0\n",
       "1  my_dataset/image2.png      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For example if our CSV file looks like this\n",
    "import pandas as pd\n",
    "train = pd.DataFrame({\"path\": [\"my_dataset/image1.png\", \"my_dataset/image2.png\"], \"label\": [0, 1] })\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create custom dataloader with csv file and DataLoader to create batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        df = pd.read_csv(csv_file)\n",
    "        self.paths = df.path.values\n",
    "        self.labels = df.label.values\n",
    "    def __getitem__(self, index):\n",
    "        # we want to be index like dataset[index]\n",
    "        # to get the index-th batch\n",
    "        img = Image.open(self.paths[index]).convert(\"RGB\")\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img, self.labels[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        # to retrieve the total samples by doing len(dataset)\n",
    "        return len(self.paths)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0d2eac5464fc2e87cb93eb40af5f568dfd8212119c3ce5d2e079388acbe40c19"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('dl22')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
