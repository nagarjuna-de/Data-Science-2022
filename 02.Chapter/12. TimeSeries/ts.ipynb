{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import pardir\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.tree          import DecisionTreeRegressor\n",
    "from sklearn.ensemble      import RandomForestRegressor\n",
    "from sklearn.ensemble      import ExtraTreesRegressor\n",
    "from sklearn.ensemble      import AdaBoostRegressor\n",
    "from sklearn.ensemble      import GradientBoostingRegressor\n",
    "from xgboost               import XGBRegressor\n",
    "from lightgbm              import LGBMRegressor\n",
    "from catboost              import CatBoostRegressor\n",
    "from sklearn.linear_model  import LinearRegression\n",
    "from sklearn import metrics \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data = pd.read_csv(r\"C:\\Users\\rnr31\\Documents\\GitHub\\Ravella_DS22_Strive_School_Excercises\\02.Chapter\\12. TimeSeries\\climate.csv\")\n",
    "data = data.drop([\"Date Time\"], axis=1)\n",
    "\n",
    "def pairing(data, seq_len=6):\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    for i in range(0,(data.shape[0] - seq_len+1), seq_len+1 ): # range is reduced by the len of seq + 1 so that we do not go out of bounds\n",
    "                                                            # we step for that same amount of steps as the seq_len\n",
    "        seq = np.zeros( (seq_len, data.shape[1]) ) #creating a matrix of zeros with the shape of seq_len and the number of columns of the data\n",
    "        \n",
    "        for j in range(seq_len):  # filling the matrix with the data\n",
    "\n",
    "            seq[j] = data.values[i+j]  # filling the matrix with the data we add i to make the jump of the seq_len\n",
    "\n",
    "        x.append(seq.flatten())  # flattening the matrix and appending it to the x list\n",
    "        y.append( data[\"T (degC)\"][i+seq_len] )  # appending the target to the y list \n",
    "\n",
    "    return np.array(x), np.array(y)\n",
    "\n",
    "#print(data.shape)\n",
    "\n",
    "x, y = pairing(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "tscv = TimeSeriesSplit(test_size=2)\n",
    "for train_index, test_index in tscv.split(x):\n",
    "    x_train, x_test = x[train_index], x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressors = {\n",
    "   \"Decision Tree\": DecisionTreeRegressor(),\n",
    "  # \"Extra Trees\":   ExtraTreesRegressor(n_estimators=100),\n",
    "   \"Random Forest\": RandomForestRegressor(n_estimators=100),\n",
    "  # \"AdaBoost\":      AdaBoostRegressor(n_estimators=100),\n",
    "  # \"Skl GBM\":       GradientBoostingRegressor(n_estimators=100),\n",
    "  # \"XGBoost\":       XGBRegressor(n_estimators=100),\n",
    "  # \"LightGBM\":      LGBMRegressor(n_estimators=100),\n",
    "  # \"CatBoost\":      CatBoostRegressor(n_estimators=100),\n",
    "  'Linear Regression' : LinearRegression()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Model       MSE       MAB   % error        Time\n",
      "1  Linear Regression  0.035095  0.187259  0.002487    1.235386\n",
      "2      Random Forest  0.046086  0.207800  0.003266  334.399595\n",
      "3      Decision Tree  0.046250  0.175000  0.003278    5.586050\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame({'Model': [], 'MSE': [], 'MAB': [], \" % error\": [], 'Time': []})\n",
    "rang = abs(y_train.max()) - abs(y_train.min())\n",
    "for model_name, model in regressors.items():\n",
    "    \n",
    "    start_time = time.time()\n",
    "    model.fit(x_train, y_train)\n",
    "    total_time = time.time() - start_time\n",
    "        \n",
    "    pred = model.predict(x_test)\n",
    "    \n",
    "    results = results.append({\"Model\":    model_name,\n",
    "                              \"MSE\": metrics.mean_squared_error(y_test, pred),\n",
    "                              \"MAB\": metrics.mean_absolute_error(y_test, pred),\n",
    "                              \" % error\": metrics.mean_squared_error(y_test, pred) / rang,\n",
    "                              \"Time\":     total_time},\n",
    "                              ignore_index=True)\n",
    "### END SOLUTION\n",
    "\n",
    "\n",
    "results_ord = results.sort_values(by=['MSE'], ascending=True, ignore_index=True)\n",
    "results_ord.index += 1 \n",
    "results_ord.style.bar(subset=['MSE', 'MAE'], vmin=0, vmax=100, color='#5fba7d')\n",
    "\n",
    "print(results_ord)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8e98eea00a698c66ff9007bd5a8bf6209cdaa78d416205c57d24ef9296d8223a"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('strive')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
